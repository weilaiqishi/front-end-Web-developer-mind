# 内存控制

## v8垃圾回收机制与内存限制

**内存问题**
Node是一个构建在Chrome的JavaScript运行时上的平台
内存控制正是在海量请求和长时间运行的前提下进行探讨的
在Node中通过 JavaScript 使用内存时就会发现只能使用部分内存（无法操作大内存对象，例如读取2G的文件）
(64位系统下约为1.4 GB,32位系统下约为0.7 GB)

**V8限制内存的原因**
开始是为浏览器设置的，不太可能会存在用到大量内存的场景
V8的垃圾回收机制限制，不控制内存会导致垃圾回收时间加长，阻塞 js 线程执行
(这个限制可以通过 v8 提供的选项解除，如
node --max-old-space-size=1700 test.js)

**V8的对象分配**
在V8中,所有的JavaScript对象都是通过堆来进行分配的
根据对象的存货时间将内存的垃圾回收进行不同的分代，分别施以高效算法
老生代中的对象为存活时间较长或常驻内存的对象
新生代中的对象为存活时间较短的对象

### V8的垃圾回收机制

- Scavenge算法：就是通过将存活对象在两个 semispace空间之间进行复制(典型的牺牲空间换取时间的算法，非常适合在生命周期短的新生代中应用)
- Mark-Sweep算法：通过标记活对象，清理死亡对象
- Mark-Compact算法：将或对象移动到老生代一端，解决内存碎片问题

V8主要使用Mark-Sweep,在空间不足以对从新生代中晋升过来的对象进行分配时才使用Mark-Compact。

垃圾回收需要将应用逻辑暂停下来即“全停顿”

垃圾回收的优化
拆分全停顿，应用执行一小会，垃圾回收执行一个拆分
延迟清理
增量式整理

## 高效使用内存

作用域

- 函数执行结束后，函数作用域被销毁，函数作用域中声明的变量也销毁
- 全局作用域需要直到进程退出才能释放
- 如果需要释放常驻内存的对象,可以通过delete操作来删除引用关系。或者将变量重新赋值,让旧的对象脱离引用关系。
(V8中通过delete删除对象的属性有可能干扰V8 的优化,所以通过赋值方式解除引用更好)

闭包

- 作用域链上的对象访问只能向上,这样外部无法向内部访问
- 实现外部作用域访问内部作用域中变量的方法叫做闭包
- 闭包使得外部作用域对闭包定义的词法作用域有引用，因此词法作用域不会释放，内存也不会释放
- 在正常的JavaScript执行中,无法立即回收的内存有闭包和全局变量引用这两种情况

## 内存监控

进程的内存总共有几部分

- rss 进程的常驻内存部分
- 交换区
- 文件系统

process.memoryUsage() 可以查看内存使用情况
堆中的内存用量总是小于进程的常驻内存用量，即内存并非都是通过V8分配的(不是通过V8分配的内 存称为堆外内存)
os.totalmem() 可以查看系统的总内存
os.freemem() 可以查看系统的闲置内存

使用`pm2 list`即可查看通过pm2运行的程序的性能指标，`strapi` 后端内存占用100MB左右

[如何监控 Node 进程的内存](https://raw.githubusercontent.com/shfshanyue/blog/master/node/mem.md)

### 进程内存监控 linux pidstat

`pidstat` 是 `sysstat` 系列 linux 性能调试工具的一个包

``` bash
# -r: 指输出内存指标
# -p: 指定 pid
# 1: 每一秒输出一次
# 100: 输出100次
$ pidstat -r -p pid 1 100
```

而在使用 `pidstat` 之前，需要先找到进程的 `pid`
在 `node` 中可以通过 `process.pid` 来找到进程的 `pid`

虽然通过写代码可以找到 `pid`，但是具有侵入性，不太实用。那如何通过非侵入的手段找到 `pid` 呢？有两种办法

1. 通过多余的参数结合 `ps` 定位进程
2. 通过端口号结合 `lsof` 定位进程

``` bash
$ node index.js shanyue

# 第一种方法：通过多余的参数快速定位 pid
$ ps -ef | grep shanyue
root     31796 23839  1 16:38 pts/5    00:00:00 node index.js shanyue

# 第二种方法：通过端口号定位 pid
lsof -i:3200
COMMAND   PID USER   FD   TYPE    DEVICE SIZE/OFF NODE NAME
node    31796 root   20u  IPv6 235987334      0t0  TCP *:tick-port (LISTEN)
```

![Linux Performance Tods](https://camo.githubusercontent.com/4e63aceeef7797e78a5f4528478c7a30458dbca2/687474703a2f2f7777772e6272656e64616e67726567672e636f6d2f506572662f6c696e75785f706572665f746f6f6c735f66756c6c2e706e67)

从以上代码中可以知道，node 服务的 pid 为 `31796`，为了可以观察到内存的动态变化，再施加一个压力测试

``` bash
$ ab -c 10000 -n 1000000 http://localhost:3200/
```

``` bash
# -r: 指输出内存指标
# -p: 指定 pid
# 1: 每一秒输出一次
# 100: 输出100次
$ pidstat -r -p 31796 1 100
Linux 3.10.0-957.21.3.el7.x86_64 (shuifeng)     2020年07月02日  _x86_64_        (2 CPU)

             UID       PID  minflt/s  majflt/s     VSZ    RSS   %MEM  Command
19时20分39秒     0     11401      0.00      0.00  566768  19800   0.12  node
19时20分40秒     0     11401      0.00      0.00  566768  19800   0.12  node
19时20分41秒     0     11401   9667.00      0.00  579024  37792   0.23  node
19时20分42秒     0     11401  11311.00      0.00  600716  59988   0.37  node
19时20分43秒     0     11401   5417.82      0.00  611420  70900   0.44  node
19时20分44秒     0     11401   3901.00      0.00  627292  85928   0.53  node
19时20分45秒     0     11401   1560.00      0.00  621660  81208   0.50  node
19时20分46秒     0     11401   2390.00      0.00  623964  83696   0.51  node
19时20分47秒     0     11401   1764.00      0.00  625500  85204   0.52  node
```

对于输出指标的含义如下

+ `RSS`: `Resident Set Size`，常驻内存集，可理解为内存，这就是我们需要监控的内存指标
+ `VSZ`: `virtual size`，虚拟内存

从输出可以看出，**当施加了压力测试后，内存由 19M 涨到了 85M。**

### 使用 top 监控内存

`pidstat` 是属于 `sysstat` 下的 linux 性能工具，但在 mac 中，如何定位内存的变化？

此时可以使用 `top/htop`

``` bash
$ htop -p 31796
```

### 内存监控原理

无论使用 `top/htop`，`pidstat` 及 `process.memoryUsage` 监控 Node 进程的内存，在 `linux` 中，其原理都是监听 `procfs` 文件变化

+ `cat /proc/100/stat`: 100 号进程的信息，以机器读的格式输出
+ `cat /proc/100/status`: 100 好进程的信息，以可读的格式输出

``` bash
# machine-readable
$ cat /proc/100/stat
100 (kauditd) S 2 0 0 0 -1 2105408 0 0 0 0 0 3455 0 0 20 0 1 0 63 0 0 18446744073709551615 0 0 0 0 0 0 0 2147483647 0 18446744072255378100 0 0 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0

# human-readable
$ cat /proc/100/status
Name:   kauditd
Umask:  0000
State:  S (sleeping)
Tgid:   100
Ngid:   0
Pid:    100
PPid:   2
TracerPid:      0
Uid:    0       0       0       0
Gid:    0       0       0       0
FDSize: 64
Groups:
Threads:        1
SigQ:   0/63460
SigPnd: 0000000000000000
ShdPnd: 0000000000000000
SigBlk: 0000000000000000
SigIgn: ffffffffffffffff
SigCgt: 0000000000000000
CapInh: 0000000000000000
CapPrm: 0000001fffffffff
CapEff: 0000001fffffffff
CapBnd: 0000001fffffffff
CapAmb: 0000000000000000
Seccomp:        0
Speculation_Store_Bypass:       vulnerable
Cpus_allowed:   3
Cpus_allowed_list:      0-1
Mems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001
Mems_allowed_list:      0
voluntary_ctxt_switches:        2353755
nonvoluntary_ctxt_switches:     26
```

### 生产环境内存监控

由于目前生产环境大都部署在 `k8s`，**因此生产环境对于某个应用的内存监控本质上是 k8s 对于某个 `workload/deployment` 的内存监控**，关于内存监控 `metric` 的数据流向大致如下:

`k8s` -> `metric server` -> `prometheus` -> `grafana`

架构图如下：

![k8s](https://camo.githubusercontent.com/371929b70ccb8f3b38410047586143399a60bb6d/68747470733a2f2f34373868356d3179726673613362626532363275376d75762d7770656e67696e652e6e6574646e612d73736c2e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30382f70726f6d6574686575735f6b756265726e657465735f6469616772616d5f6f766572766965772e706e67)

> 以上图片取自以下文章
> + [Kubernetes Monitoring with Prometheus](https://sysdig.com/blog/kubernetes-monitoring-prometheus/)
> + [Kubernetes monitoring architecture](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/monitoring_architecture.md)

最终能够在 `grafana` 中收集到某一应用的内存监控实时图

## 内存泄露与排查

慎将内存当做缓存

- 在 node 中一旦一个对象被缓存起来，就会被放到老生代中
- 长期存在的对象会使得垃圾回收扫描整理的时候对这些对象做无用功
- 由于模块的缓存机制,模块是常驻老生代的
- 采用进程外的缓存,进程自身不存储状态

关注队列外状态

- 一旦消费速度低于生产速度, 将会形成堆积
- 启用超时模式时,调用加入到队列中就开始计时,超时就直接响应一个超时错误
- 拒绝模式时,当队列拥塞时,新到来的调用会直接响应拥塞错误

### 排查

node-heapdump
node-memwatch
通过对堆内存进行分析而找到

## 大内存应用

由于Node的内存限制,操作大文件 也需要小心,好在Node提供了stream模块用于处理大文件。
